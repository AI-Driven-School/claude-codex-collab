# ベンチマーク理論値（要実測検証）

## 前提条件

### トークン価格（2025年1月時点）

| AI | Input | Output | 月額 |
|----|-------|--------|------|
| Claude (Sonnet) | $3/1M | $15/1M | 従量課金 |
| Claude (Opus) | $15/1M | $75/1M | 従量課金 |
| Codex (GPT-4o) | - | - | ChatGPT Pro $200/月に含む |
| Gemini | - | - | 無料 |

### タスク別推定トークン数

| タスク | Input | Output | 合計 |
|--------|-------|--------|------|
| TODOアプリ | ~1,000 | ~3,000 | ~4,000 |
| 認証API | ~1,500 | ~5,000 | ~6,500 |
| ダッシュボード | ~2,000 | ~8,000 | ~10,000 |

---

## 理論コスト比較

### Claude Code 単体（Sonnet）

| タスク | Input Cost | Output Cost | 合計 |
|--------|------------|-------------|------|
| TODOアプリ | $0.003 | $0.045 | **$0.048** |
| 認証API | $0.0045 | $0.075 | **$0.080** |
| ダッシュボード | $0.006 | $0.120 | **$0.126** |
| **合計** | | | **$0.254** |

### 3AI連携（Claude設計 + Codex実装）

| タスク | Claude (設計のみ) | Codex | 合計 |
|--------|------------------|-------|------|
| TODOアプリ | $0.015 | $0 | **$0.015** |
| 認証API | $0.025 | $0 | **$0.025** |
| ダッシュボード | $0.030 | $0 | **$0.030** |
| **合計** | | | **$0.070** |

### コスト削減率

```
Claude単体: $0.254
3AI連携:    $0.070
削減:       $0.184 (72%削減)
```

---

## 理論時間比較（推定）

| タスク | Claude単体 | Codex単体 | 差 |
|--------|-----------|-----------|-----|
| TODOアプリ | ~90秒 | ~45秒 | 2倍速 |
| 認証API | ~150秒 | ~60秒 | 2.5倍速 |
| ダッシュボード | ~240秒 | ~90秒 | 2.7倍速 |

※ Codexの速度優位性はXでの報告に基づく推定。要実測。

---

## 注意事項

1. **これは理論値**です。実測が必要。
2. Claude Opusを使うとコストは5倍になる
3. Codexは「ChatGPT Proに含む」が前提（$200/月）
4. 設計フェーズのみClaudeを使う想定
5. 複雑なタスクほど差が大きくなる傾向

---

## 実測方法

```bash
cd benchmarks
./run-benchmark.sh claude  # Claude単体
./run-benchmark.sh codex   # Codex単体
./run-benchmark.sh all     # 両方
```

結果は `benchmarks/results/` に保存される。
